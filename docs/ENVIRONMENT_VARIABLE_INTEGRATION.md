# Environment Variable Integration for Custom VLM Configuration

## ‚úÖ Integration Complete

Environment variable support for URL + API Key + Model Name configuration has been successfully integrated into the UnifiedVLMClient.

## üéØ Features Implemented

### 1. Automatic Environment Variable Reading

The system now automatically reads custom VLM configuration from environment variables:

```bash
CUSTOM_VLM_BASE_URL=https://api.example.com/v1
CUSTOM_VLM_API_KEY=your-api-key
CUSTOM_VLM_MODEL_NAME=your-model-name
```

### 2. Seamless Integration

- **Auto Backend Selection**: When `VLMBackend.AUTO` is used, the system will automatically select the custom backend if environment variables are set
- **Explicit Custom Backend**: When `VLMBackend.CUSTOM` is specified, the system reads from environment variables if no explicit `custom_config` is provided
- **Precedence**: Explicit `custom_config` parameter takes precedence over environment variables

### 3. Usage Patterns

#### Pattern 1: Auto Selection with Environment Variables
```python
# Automatically uses custom backend if env vars are set
client = UnifiedVLMClient(backend=VLMBackend.AUTO)
```

#### Pattern 2: Explicit Custom Backend with Environment Variables
```python
# Reads configuration from environment variables
client = UnifiedVLMClient(backend=VLMBackend.CUSTOM)
```

#### Pattern 3: Explicit Configuration (Takes Precedence)
```python
# Explicit configuration overrides environment variables
client = UnifiedVLMClient(
    backend=VLMBackend.CUSTOM,
    custom_config={
        "base_url": "https://override.example.com/v1",
        "api_key": "override-key",
        "model_name": "override-model"
    }
)
```

## üîß Environment Variable Names

| Variable Name | Description | Required |
|---------------|-------------|----------|
| `CUSTOM_VLM_BASE_URL` | API endpoint URL | ‚úÖ Yes |
| `CUSTOM_VLM_API_KEY` | Authentication API key | ‚úÖ Yes |
| `CUSTOM_VLM_MODEL_NAME` | Model identifier | ‚úÖ Yes |

## üöÄ Usage Examples

### Command Line
```bash
export CUSTOM_VLM_BASE_URL=https://api.example.com/v1
export CUSTOM_VLM_API_KEY=your-api-key
export CUSTOM_VLM_MODEL_NAME=your-model-name

python your_script.py
```

### .env File
```env
CUSTOM_VLM_BASE_URL=https://api.example.com/v1
CUSTOM_VLM_API_KEY=your-api-key
CUSTOM_VLM_MODEL_NAME=your-model-name
```

### Docker
```dockerfile
FROM python:3.9

ENV CUSTOM_VLM_BASE_URL=https://api.example.com/v1
ENV CUSTOM_VLM_API_KEY=your-api-key
ENV CUSTOM_VLM_MODEL_NAME=your-model-name

COPY . /app
WORKDIR /app
CMD ["python", "your_script.py"]
```

### Python (Programmatic)
```python
import os
from holodeck_core.scene_analysis.clients.unified_vlm import UnifiedVLMClient, VLMBackend

# Set environment variables
os.environ['CUSTOM_VLM_BASE_URL'] = 'https://api.example.com/v1'
os.environ['CUSTOM_VLM_API_KEY'] = 'your-api-key'
os.environ['CUSTOM_VLM_MODEL_NAME'] = 'your-model-name'

# Use custom backend (reads from env vars)
client = UnifiedVLMClient(backend=VLMBackend.CUSTOM)

# Generate images with standardized prompts
reference_image = await client.generate_reference_image(
    description="A modern living room",
    style="realistic"
)
```

## üîÑ Integration with Standardized Prompts

The environment variable integration works seamlessly with the standardized prompt templates:

```python
import asyncio
import os
from holodeck_core.scene_analysis.clients.unified_vlm import UnifiedVLMClient, VLMBackend

async def main():
    # Set environment variables
    os.environ['CUSTOM_VLM_BASE_URL'] = 'https://api.example.com/v1'
    os.environ['CUSTOM_VLM_API_KEY'] = 'your-api-key'
    os.environ['CUSTOM_VLM_MODEL_NAME'] = 'your-model-name'

    # Initialize client (auto-reads from env vars)
    client = UnifiedVLMClient(backend=VLMBackend.CUSTOM)

    # Generate reference image with English prompt
    reference_en = await client.generate_reference_image(
        description="A modern living room with sofa, coffee table, and TV",
        style="realistic",
        language="en"
    )

    # Generate reference image with Chinese prompt
    reference_zh = await client.generate_reference_image(
        description="‰∏Ä‰∏™Áé∞‰ª£ÂåñÁöÑÂÆ¢ÂéÖÔºåÈÖçÊúâÊ≤ôÂèë„ÄÅÂíñÂï°Ê°åÂíåÁîµËßÜ",
        style="ÂÜôÂÆû",
        language="zh"
    )

    # Generate object image with auto-detection
    object_image = await client.generate_object_image(
        obj_name="modern sofa",
        style="realistic",
        reference_context="A modern living room"
        # language=None (auto-detection)
    )

    print(f"Generated {len(reference_en)} bytes (English)")
    print(f"Generated {len(reference_zh)} bytes (Chinese)")
    print(f"Generated {len(object_image)} bytes (Object)")

asyncio.run(main())
```

## üß™ Testing Coverage

### Unit Tests (7 tests)
- ‚úÖ Custom backend from environment variables
- ‚úÖ Custom backend when environment variables are not available
- ‚úÖ Custom backend with partial environment variables
- ‚úÖ Explicit config precedence over environment variables
- ‚úÖ Error handling for missing environment variables
- ‚úÖ Auto backend selection with custom environment variables
- ‚úÖ Environment variable name validation

### Integration Tests (6 tests)
- ‚úÖ Reference image generation with standardized prompts
- ‚úÖ Object image generation with standardized prompts
- ‚úÖ Auto language detection in image generation
- ‚úÖ Prompt template manager integration
- ‚úÖ Production pipeline integration
- ‚úÖ Multilingual production pipeline

**Total: 13 tests, 100% pass rate** ‚úÖ

## üîç Backend Detection Logic

The system uses the following logic to determine backend availability:

```python
def _is_backend_available(self, backend: VLMBackend) -> bool:
    if backend == VLMBackend.CUSTOM:
        # Check explicit configuration first
        if self.custom_config:
            required_keys = ['base_url', 'api_key', 'model_name']
            return all(key in self.custom_config for key in required_keys)

        # Check environment variables
        base_url = os.getenv("CUSTOM_VLM_BASE_URL")
        api_key = os.getenv("CUSTOM_VLM_API_KEY")
        model_name = os.getenv("CUSTOM_VLM_MODEL_NAME")
        return bool(base_url and api_key and model_name)
```

## üîÑ Auto-Selection Priority

When using `VLMBackend.AUTO`, the system selects backends in this order:

1. **Custom** (if environment variables OR explicit config are available)
2. **SiliconFlow** (if SILICONFLOW_API_KEY is set)
3. **OpenAI** (if OPENAI_API_KEY is set)
4. **Error** (if no backends are available)

## üö® Error Handling

### Missing Environment Variables
```python
# Raises: ValueError: Requested backend VLMBackend.CUSTOM is not available
client = UnifiedVLMClient(backend=VLMBackend.CUSTOM)
await client.generate_reference_image(...)
```

### Partial Environment Variables
```python
# If only some env vars are set, backend is not considered available
os.environ['CUSTOM_VLM_BASE_URL'] = 'https://api.example.com/v1'
os.environ['CUSTOM_VLM_API_KEY'] = 'your-api-key'
# Missing CUSTOM_VLM_MODEL_NAME

# Backend will not be available
client = UnifiedVLMClient(backend=VLMBackend.CUSTOM)
```

## üìÅ Files Modified

- `holodeck_core/scene_analysis/clients/unified_vlm.py` ‚úÖ
  - Added environment variable reading in `_is_backend_available()`
  - Added environment variable fallback in custom backend initialization
  - Enhanced error messages for better debugging

## üéâ Benefits Achieved

1. **Zero-Configuration Setup**: Users can configure custom VLM by simply setting environment variables
2. **Production Ready**: Environment variables are the standard for production deployments
3. **Docker Friendly**: Perfect integration with Docker and containerized deployments
4. **Security**: API keys are not hardcoded in source code
5. **Flexibility**: Easy to switch between different custom backends
6. **Backward Compatible**: Existing code continues to work unchanged

## üîÆ Future Enhancements

1. **Additional Environment Variables**:
   - `CUSTOM_VLM_TIMEOUT`: Request timeout configuration
   - `CUSTOM_VLM_HEADERS`: Custom HTTP headers
   - `CUSTOM_VLM_LANGUAGE`: Default language preference

2. **Configuration Validation**:
   - Validate URL format
   - Test API connectivity at startup
   - Validate model name availability

3. **Multiple Custom Backends**:
   - Support for multiple custom backend configurations
   - Dynamic backend selection based on workload

## ‚úÖ Conclusion

Environment variable integration for URL + API Key + Model Name configuration is now **complete and production-ready**! The system provides:

- ‚úÖ **Automatic environment variable reading**
- ‚úÖ **Seamless integration with standardized prompts**
- ‚úÖ **Full backward compatibility**
- ‚úÖ **Comprehensive testing coverage**
- ‚úÖ **Multiple usage patterns**
- ‚úÖ **Production deployment ready**

The implementation follows best practices for environment variable usage and provides a robust foundation for custom VLM integration in any deployment environment! üöÄ