"""Asset metadata schemas for the Object Generation module.

Tracks 3D asset generation results from image-to-3D models like Hunyuan3D 2.1.
"""

from typing import List, Optional, Literal, Dict, Any
from datetime import datetime, timezone
from pydantic import BaseModel, Field, model_validator, ConfigDict

from .scene_objects import Vec3


class AssetMetadata(BaseModel):
    """Metadata for a single generated 3D asset.

    Includes the GLB file path, normalization info, and generation details.
    """
    object_id: str = Field(..., description="Object identifier")
    object_name: str = Field(..., description="Object name")
    source_card_path: str = Field(..., description="Path to source object card image")

    # Generated asset info
    glb_path: str = Field(..., description="Path to generated GLB file")
    file_size_mb: float = Field(..., ge=0.0, description="File size in megabytes")

    # Size and scaling information
    original_size: Vec3 = Field(..., description="Size as generated by the model")
    normalized_size: Vec3 = Field(..., description="Size after scaling to match constraints")
    scaling_factor: float = Field(1.0, ge=0.0, description="Scale factor applied")

    # Position and pivot info
    pivot_point: Vec3 = Field(default_factory=lambda: Vec3(x=0.5, y=0.5, z=0.0), description="Normalized pivot point (0-1, 0-1, Z)")

    # Generation metadata
    generation_time: float = Field(..., ge=0.0, description="Time taken for generation (seconds)")
    generation_status: Literal["success", "failed"] = Field(..., description="Generation status")
    failure_reason: Optional[str] = Field(None, description="Reason for failure if applicable")

    # Model information
    model_name: str = Field("Hunyuan3D-2.1", description="Name of generation model")
    model_version: str = Field("2.1", description="Version of generation model")

    # Quality metrics
    quality_score: Optional[float] = Field(None, ge=0.0, le=1.0, description="Quality assessment score")
    vertex_count: Optional[int] = Field(None, ge=0, description="Number of vertices in the model")

    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc), description="Generation timestamp")

    model_config = ConfigDict(
        str_strip_whitespace=True,
        validate_assignment=True,
        json_schema_extra={
            "reference": "HOLODECK 2.0 Supp 6.3 - Object Generation Module",
            "examples": [
                {
                    "object_id": "bed1",
                    "object_name": "King Bed",
                    "source_card_path": "object_cards/bed1.png",
                    "glb_path": "assets/bed1.glb",
                    "file_size_mb": 12.4,
                    "original_size": {"x": 2.1, "y": 1.9, "z": 1.1},
                    "normalized_size": {"x": 2.0, "y": 1.5, "z": 0.6},
                    "scaling_factor": 0.714,
                    "generation_time": 45.2,
                    "generation_status": "success",
                    "quality_score": 0.87,
                    "vertex_count": 8542
                }
            ]
        }
    )

    @model_validator(mode='after')
    def validate_scaling_consistency(self):
        """Ensure scaling factor matches size ratios."""
        if self.generation_status == "success":
            for axis in ['x', 'y', 'z']:
                orig_val = getattr(self.original_size, axis)
                norm_val = getattr(self.normalized_size, axis)
                expected_factor = norm_val / orig_val if orig_val > 0 else 0

                if abs(expected_factor - self.scaling_factor) > 0.001:
                    raise ValueError(
                        f"Scaling factor mismatch for {axis}: "
                        f"{norm_val}/{orig_val}={expected_factor} != {self.scaling_factor}"
                    )
        return self

    def validate_failure_state(self):
        """Set defaults for failed generation."""
        if self.generation_status == "failed" and not self.glb_path:
            # Only set defaults if not already provided
            self.glb_path = ""
            self.file_size_mb = 0.0
            self.scaling_factor = 0.0
            self.quality_score = None
            self.vertex_count = None
        return self


class AssetBatch(BaseModel):
    """Batch generation metadata for multiple assets.

    Tracks parallel generation of all object assets for a scene.
    """
    batch_id: str = Field(..., description="Unique batch identifier")
    scene_session_id: str = Field(..., description="Associated scene session ID")

    # Batch configuration
    total_assets: int = Field(..., ge=1, description="Total number of assets to generate")
    parallel_workers: int = Field(1, ge=1, le=8, description="Number of parallel workers used")

    # Results
    successful_assets: List[AssetMetadata] = Field(..., description="Successfully generated assets")
    failed_assets: List[Dict[str, Any]] = Field(default_factory=list, description="Failed generation attempts")

    # Performance metrics
    total_time: float = Field(..., ge=0.0, description="Total batch time in seconds")
    avg_generation_time: float = Field(0.0, ge=0.0, description="Average time per asset")
    parallel_efficiency: float = Field(1.0, ge=0.0, le=1.0, description="Efficiency factor (serial_time / parallel_time)")

    # Summary
    success_count: int = Field(0, description="Number of successful generations")
    success_rate: float = Field(0.0, ge=0.0, le=1.0, description="Success rate fraction")
    total_model_size: float = Field(0.0, ge=0.0, description="Total size of all models (MB)")
    total_vertices: int = Field(0, ge=0, description="Total vertices across all models")

    started_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc), description="Start timestamp")
    completed_at: Optional[datetime] = Field(None, description="Completion timestamp")

    model_config = ConfigDict(
        validate_assignment=True,
        json_schema_extra={
            "examples": [
                {
                    "batch_id": "asset_batch_20260112_123456",
                    "scene_session_id": "2026-01-12T12-30-05Z_abc123",
                    "total_assets": 5,
                    "parallel_workers": 3,
                    "successful_assets": [
                        {
                            "object_id": "bed1",
                            "glb_path": "assets/bed1.glb",
                            "generation_status": "success"
                        }
                    ],
                    "total_time": 180.5,
                    "success_rate": 0.8
                }
            ]
        }
    )

    def calculate_metrics(self):
        """Calculate derived metrics without recursion."""
        success_count = len(self.successful_assets)
        success_rate = success_count / self.total_assets

        # Calculate average generation time
        if success_count > 0:
            times = [a.generation_time for a in self.successful_assets]
            avg_generation_time = sum(times) / len(times)
        else:
            avg_generation_time = 0.0

        # Calculate total sizes
        total_model_size = sum(a.file_size_mb for a in self.successful_assets)
        total_vertices = sum(
            a.vertex_count or 0
            for a in self.successful_assets
            if a.vertex_count is not None
        )

        return {
            "success_count": success_count,
            "success_rate": success_rate,
            "avg_generation_time": avg_generation_time,
            "total_model_size": total_model_size,
            "total_vertices": total_vertices
        }

    @model_validator(mode='after')
    def validate_failed_assets(self):
        """Ensure failed assets have correct structure."""
        for failed in self.failed_assets:
            required_fields = ['object_id', 'object_name', 'failure_reason']
            for field in required_fields:
                if field not in failed:
                    raise ValueError(f"Failed asset missing required field: {field}")
        return self


class AssetNormalizationConfig(BaseModel):
    """Configuration for asset normalization."""
    z_axis_reference: bool = Field(True, description="Use Z-axis size as reference for scaling")
    preserve_proportions: bool = Field(True, description="Maintain aspect ratios during scaling")
    min_scale_factor: float = Field(0.1, ge=0.01, le=1.0, description="Minimum allowed scale factor")
    max_scale_factor: float = Field(5.0, ge=1.0, le=100.0, description="Maximum allowed scale factor")

    model_config = ConfigDict(
        validate_assignment=True,
        json_schema_extra={
            "examples": [
                {
                    "z_axis_reference": True,
                    "preserve_proportions": True,
                    "min_scale_factor": 0.1,
                    "max_scale_factor": 5.0
                }
            ]
        }
    )